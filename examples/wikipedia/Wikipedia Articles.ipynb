{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b611933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /home/delta/.local/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/lib/python3/dist-packages (from wikipedia) (2.22.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/delta/.local/lib/python3.8/site-packages (from wikipedia) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/delta/.local/lib/python3.8/site-packages (from beautifulsoup4->wikipedia) (2.3.1)\n",
      "Requirement already satisfied: lxml in /home/delta/.local/lib/python3.8/site-packages (4.6.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3030e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "import wikipedia\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2035a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infobox(term):\n",
    "    url = \"https://en.wikipedia.org/wiki/\" + term\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    tbl = soup.find(\"table\", {\"class\": \"infobox\"})\n",
    "    if not tbl:\n",
    "        return {}\n",
    "    list_of_table_rows = tbl.findAll(\"tr\")\n",
    "    info = {}\n",
    "    for tr in list_of_table_rows:\n",
    "        th = tr.find(\"th\")\n",
    "        td = tr.find(\"td\")\n",
    "        if th is not None and td is not None:\n",
    "            innerText = \"\"\n",
    "            for elem in td.recursiveChildGenerator():\n",
    "                if isinstance(elem, str):\n",
    "                    # remove references\n",
    "                    clean = re.sub(\"([\\[]).*?([\\]])\", \"\\g<1>\\g<2>\", elem.strip())\n",
    "                    # add a simple space after removing references for word-separation\n",
    "                    innerText += clean.replace(\"[]\", \"\") + \" \"\n",
    "                elif elem.name == \"br\":\n",
    "                    innerText += \"\\n\"\n",
    "            info[th.text] = innerText\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04661ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_sections(body):\n",
    "    sections = {}\n",
    "    start = True\n",
    "    for sec in body.split('\\n\\n\\n== '):\n",
    "        if start:\n",
    "            sections['Description'] = sec\n",
    "            start = False\n",
    "            continue    \n",
    "        # get name\n",
    "        ind = sec.find('\\n')\n",
    "        if ind < 0:\n",
    "            continue\n",
    "        name = sec[:ind]\n",
    "        sections[name[: name.rfind(' ')]] = sec.replace(name, '').lstrip('\\n')\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26fb44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wikipedia(topic):\n",
    "    page = wikipedia.page(topic)\n",
    "\n",
    "    # get the title of the page\n",
    "    return {\n",
    "        \"name\": page.title,\n",
    "        \"categories\": page.categories,\n",
    "        \"body\": page.content,\n",
    "        \"links\": page.links,\n",
    "        \"references\": page.references,\n",
    "        \"summary\": page.summary,\n",
    "        \"sections\": get_wiki_sections(page.content),\n",
    "        \"infobox\": extract_infobox(topic)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6363386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(wiki, name):\n",
    "    values = {\n",
    "        \"name\": name,\n",
    "        \"body\": \"\",\n",
    "    }\n",
    "    group_children = []\n",
    "    for group, pages in wiki.items():\n",
    "        subval = {\n",
    "            \"name\": group,\n",
    "            \"body\": \"\",\n",
    "        }\n",
    "        children = []\n",
    "        for page in pages:\n",
    "            children.append(extract_wikipedia(page))\n",
    "        subval['children'] = children\n",
    "        group_children.append(subval)\n",
    "    values['children'] = group_children\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5632c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "therapies = {\n",
    "    \"psychodynamic and humanistic psychotherapies\":[\n",
    "        \"psychoanalysis\",\n",
    "        \"psychodynamic psychotherapy\",\n",
    "        \"humanistic psychotherapy\",\n",
    "    ],\n",
    "    \"behavioral and cognitive-behavior psychotherapies\":[\n",
    "        \"behaviour therapy\",\n",
    "        \"cognitive therapy\",\n",
    "        \"cognitive behavioral therapy\",\n",
    "    ],\n",
    "    \"other modes of clinical intervention\":[\n",
    "        \"group therapy\",\n",
    "        \"couples therapy\",\n",
    "        \"family therapy\",\n",
    "        \"community psychology\",\n",
    "        \"self-help\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed74fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "therapy_data = extraction(therapies, 'basic_therapies')\n",
    "with open('data/basic_therapies.json', 'w+') as f:\n",
    "    json.dump(therapy_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0e4d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_lining = {\n",
    "    \"psychotic drugs\":[\n",
    "        \"Aripiprazole\",\n",
    "        \"Quetiapine\",\n",
    "    ],\n",
    "    \"Bipolar disorder drugs\":[\n",
    "        \"Lithium salts\",\n",
    "    ],\n",
    "    \"anxiety disorder drugs\":[\n",
    "        \"Alprazolam\",\n",
    "        \"Clonazepam\",\n",
    "        \"Trazodone\",\n",
    "    ],\n",
    "    \"depressive disorder drugs\":[\n",
    "        \"Venlafaxine\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "data = extraction(silver_lining, 'silver_lining_drugs')\n",
    "with open('data/silver_lining_drugs.json', 'w+') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ac02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
