{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb2ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (1.24)\n",
      "Requirement already satisfied: pyyaml in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (6.0)\n",
      "Requirement already satisfied: requests in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (from tika) (2.27.0)\n",
      "Requirement already satisfied: setuptools in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (from tika) (56.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (from requests->tika) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (from requests->tika) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (from requests->tika) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (from requests->tika) (2021.10.8)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/delta/Desktop/meta/ontology-graphs/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: regex in /home/delta/Desktop/meta/ontology-graphs/venv/lib/python3.8/site-packages (2021.11.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/delta/Desktop/meta/ontology-graphs/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tika pyyaml\n",
    "!pip install regex\n",
    "# !jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bd15c",
   "metadata": {},
   "source": [
    "## Read PDF into python-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345ef1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml\n",
    "import json\n",
    "import regex\n",
    "\n",
    "# parsing the pdf\n",
    "from tika import parser \n",
    "\n",
    "# turning stuff to a tree\n",
    "from anytree import Node, RenderTree, AsciiStyle, PostOrderIter\n",
    "from anytree.importer import DictImporter\n",
    "from anytree.exporter import DictExporter\n",
    "from anytree.search import findall\n",
    "\n",
    "DSM_V_location = './raw/DSM_V.pdf'\n",
    "DSM_ToC_location = './raw/toc.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49decc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = parser.from_file(DSM_V_location)\n",
    "content = raw['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7c4e9",
   "metadata": {},
   "source": [
    "## Process Table of Contents for controlling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc04f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DSM_ToC_location) as f:\n",
    "    # use safe_load instead load\n",
    "    ToC = {\"name\": \"DSM_V\", \"id\":\"100000\", 'children': yaml.safe_load(f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af39ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = DictImporter()\n",
    "exporter = DictExporter()\n",
    "toc_node = importer.import_(ToC)\n",
    "id = 100001\n",
    "for node in PostOrderIter(toc_node):\n",
    "    while '  ' in node.name:\n",
    "        node.name = node.name.replace('  ', ' ')  \n",
    "    setattr(node, 'id', str(id))\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98410f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw/toc.json', 'w+') as f:\n",
    "    json.dump(exporter.export(toc_node), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab64d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(content):\n",
    "    name = ' '.join([\n",
    "        k for k in content.split('\\n') \n",
    "        if len(k) > 0 and k[0].isupper()\n",
    "    ])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb2b2a5",
   "metadata": {},
   "source": [
    "## Find Disorders that have an organized structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f92c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible stuff found inside a block describing a disorder\n",
    "SECTIONS = [\n",
    "    'Diagnostic Criteria',\n",
    "    'Recording Procedures',\n",
    "    'Specifiers',  \n",
    "    'Diagnostic Features',\n",
    "    'Associated Features Supporting Diagnosis',\n",
    "    'Prevalence',\n",
    "    'Development and Course',\n",
    "    'Risk and Prognostic Factors',\n",
    "    'Culture-Related Diagnostic Issues',\n",
    "    'Gender-Related Diagnostic Issues',\n",
    "    'Functional Consequences of',\n",
    "    'Differential Diagnosis',\n",
    "    'Comorbidity',\n",
    "    'Relationship to Other Classifications',\n",
    "]\n",
    "\n",
    "# step by step information about diagnostic criteria\n",
    "STEPS = [\n",
    "    'Diagnostic Criteria', 'Coding note:', 'Specify if:', 'Specify whether:',\n",
    "    'A.', 'B.', 'C.', 'D.', 'E.',\n",
    "    'F.', 'G.', 'H.', 'I.', 'J.',\n",
    "]\n",
    "SUBSTEPS = [\"1.\", \"2.\", \"3.\", \"4.\", \"5.\", \"6.\", \"7.\", \"8.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6924ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(content, steps=SECTIONS):\n",
    "    \"\"\"Helper function separating the text into blocks of information\n",
    "    based on the expected steps that should be included.\"\"\"\n",
    "\n",
    "    base = {}\n",
    "    previous_step = \"\"\n",
    "    data = []\n",
    "    found_steps = []\n",
    "    for row in content.split(\"\\n\"):\n",
    "        for step in steps:\n",
    "            if step in found_steps:\n",
    "                continue\n",
    "            found = regex.findall(\n",
    "                \"(\" + step + \"){e<=3}\", row[: len(step) + 3], overlapped=True\n",
    "            )\n",
    "            if row.startswith(step) or row == step or len(found):\n",
    "                base[previous_step] = \"\\n\".join(data)\n",
    "                previous_step = step\n",
    "                data = []\n",
    "                found_steps.append(step)\n",
    "        data.append(row)\n",
    "    base[previous_step] = \"\\n\".join(data)\n",
    "    if \"\" in base:\n",
    "        del base[\"\"]\n",
    "    return base\n",
    "\n",
    "\n",
    "def create_structure(content, steps):\n",
    "    \"\"\"Sub-section list filtering.\n",
    "    Example: 1. 2. 3.\n",
    "    Example: A. B. C.\n",
    "    \"\"\"\n",
    "\n",
    "    for each in steps:\n",
    "        content = content.replace(each, \"\\n\" + each)\n",
    "    base = {}\n",
    "    previous_step = \"Beginning\"\n",
    "    data = []\n",
    "    for row in content.split(\"\\n\"):\n",
    "        for step in steps:\n",
    "            if step in row:\n",
    "                base[previous_step] = \"\\n\".join(data).replace(\"\\n\\n\", \"-\")\n",
    "                previous_step = step\n",
    "                data = []\n",
    "        data.append(row)\n",
    "    base[previous_step] = \"\\n\".join(data)\n",
    "    if \"\" in base:\n",
    "        del base[\"\"]\n",
    "    return base\n",
    "\n",
    "\n",
    "def structure_body(content, steps=STEPS, subsections=SUBSTEPS):\n",
    "    structured = create_structure(content, steps)\n",
    "    for each, val in structured.items():\n",
    "        sub = create_structure(val, substeps)\n",
    "        structured[each] = \"\\n\".join(sub.values())\n",
    "    return \"\\n\\n\".join(structured.values())\n",
    "\n",
    "\n",
    "def create_sections(content, sections=SECTIONS, structured=['Diagnostic Criteria']):\n",
    "    sections = get_sections(content, steps)\n",
    "    for key, val in sections.items():\n",
    "        if key in structured:\n",
    "            sections[key] = structure_body(val)\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f3ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous = None\n",
    "next_name = None\n",
    "structured_disorders = []\n",
    "\n",
    "for i in re.finditer(r'^Diagnostic Criteria', content, flags=re.MULTILINE):\n",
    "\n",
    "    # decide name of disorder based on previous lines\n",
    "    diag_start = i.span()[0]\n",
    "\n",
    "    # skip first time, and store text there\n",
    "    if previous is None:\n",
    "        next_name = get_name(content[diag_start-80:diag_start])\n",
    "        previous = diag_start\n",
    "        continue\n",
    "\n",
    "    # decide naming\n",
    "    name = next_name \n",
    "    next_name = get_name(content[diag_start-80:diag_start])\n",
    "    \n",
    "    # get content of disorder\n",
    "    text = content[previous:diag_start].replace(name, '')\n",
    "    disorder = {}\n",
    "    disorder['body'] = text\n",
    "    disorder['sections'] = get_sections(text)\n",
    "    disorder['name'] = name.replace('  ', ' ')\n",
    " \n",
    "    # prepare for next round\n",
    "    previous = diag_start\n",
    "\n",
    "    # skip problematic runs\n",
    "    if len(disorder.keys()) < 2:\n",
    "        continue\n",
    "    structured_disorders.append(disorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72e9b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(structured_disorders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48de947",
   "metadata": {},
   "source": [
    "### Post-Processing\n",
    "* some extracted data have no name, check by hand their cases\n",
    "* some names have issues\n",
    "* some names include too much, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46c5b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1 = 'Note: A tic is a sudden, rapid, recurrent, nonrhythmic motor movement or vocalization.'\n",
    "diag2 = 'A. The development of a reversible substance-specific syndrome attributable to recent in'\n",
    "diag3 = 'A. Daily use of tobacco for at least several weeks.'\n",
    "diag4 = 'A. Following cessation of use of a hallucinogen, the reexperiencing of one or more of the'\n",
    "diag5 = 'A. Presence of obsessions, compulsions, or both'\n",
    "diag6 = 'C. The cognitive deficits do not occur exclusively in the context of a delirium.'\n",
    "diag7 = 'A. Lack of, or significantly reduced, sexual interest/arousal, as manifested by at least '\n",
    "diag8 = 'A. Polysomnograpy demonstrates episodes of decreased respiration associated with el'\n",
    "\n",
    "empty_name_fix = {\n",
    "    'Tic Disorders': diag1,\n",
    "    'Other (or Unknown) Substance Intoxication': diag2,\n",
    "    'Tobacco Withdrawal': diag3,\n",
    "    'Hallucinogen Persisting Perception Disorder': diag4,\n",
    "    'Obsessive-Compulsive Disorder': diag5,\n",
    "    'Mild Neurocognitive Disorder': diag6,\n",
    "    'Female Sexual Interest/Arousal Disorder': diag7,\n",
    "    'Sleep-Related Hypoventilation': diag8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee5d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_name(name):\n",
    "    \"\"\"Removing unneeded variations of names that doesnt allow coordination\n",
    "    between extracted info and table of contents. \n",
    "    This has been done post processing, but its \n",
    "    being written here for keeping clean.\"\"\"\n",
    "\n",
    "    name = name[name.rfind('.')+1:]\n",
    "    return (\n",
    "        name.replace('l\\/l', 'M')\n",
    "        .replace('IVI', 'M')\n",
    "        .replace('Disinhiblted', 'Disinhibited')\n",
    "        .replace('Dereallzation', 'Derealization')\n",
    "        .replace('-induced', '-Induced')\n",
    "        .replace('Reiated', 'Related')\n",
    "        .replace('Genlto', 'Genito')\n",
    "        .replace('A positive family history ', '')\n",
    "        .replace(\n",
    "            'Unspecified Tobacco-Related Disorder Tobacco Use Disorder',\n",
    "            'Tobacco Use Disorder'\n",
    "        )\n",
    "        .replace(\n",
    "            'Unspecified Stimulant-Related Disorder Stimulant Use Disorder',\n",
    "            'Stimulant Use Disorder'\n",
    "        )\n",
    "        .replace(\n",
    "            'Induced Disorders Unspecified Inhalant-Related Disorder Inhalant Use Disorder',\n",
    "            'Inhalant Use Disorder'\n",
    "        )\n",
    "        .replace(\n",
    "            'Disorder Unspecified Hallucinogen-Related Disorder Phencyclidine Use Disorder',\n",
    "            'Phencyclidine Use Disorder'\n",
    "        )\n",
    "        .replace(\n",
    "            'Induced Disorders Unspecified Cannabis-Related Disorder Cannabis Use Disorder',\n",
    "            'Cannabis Use Disorder'\n",
    "        )\n",
    "        .replace(\n",
    "            'Unspecified Alcohol-Related Disorder Alcohol Use Disorder',\n",
    "            'Alcohol Use Disorder'\n",
    "        )\n",
    "        .replace(\n",
    "            'Induced Disorders Unspecified Caffeine-Related Disorder Caffeine Intoxication',\n",
    "            'Caffeine Intoxication'\n",
    "        )\n",
    "        .replace(\n",
    "            'Disorder Attention-Deficit/Hyperactivity Disorder',\n",
    "            'Attention-Deficit/Hyperactivity Disorder Attention-Deficit/Hyperactivity Disorder'\n",
    "        )\n",
    "    ).lstrip()\n",
    "\n",
    "\n",
    "def fix_empty_name_disorders(disorder):\n",
    "    \"\"\"fix cases where the name is empty.\"\"\"\n",
    "    for disorder_name, diagnosis in empty_name_fix.items():\n",
    "        if diagnosis in disorder['body']:\n",
    "            return disorder_name\n",
    "    return \"\"\n",
    "    # raise Exception('Disorder Not Found in Post Processing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53291b",
   "metadata": {},
   "source": [
    "## Turn the processed disorders into a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da1dd8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Disease 'Section II' was not found in Table of Contents.\n",
      "Error: Disease 'Elements of a Diagnosis ' was not found in Table of Contents.\n"
     ]
    }
   ],
   "source": [
    "for disorder in structured_disorders:\n",
    "    involved_nodes = []\n",
    "    \n",
    "    # fix name issues\n",
    "    disorder['name'] = fix_name(disorder['name'])\n",
    "\n",
    "    # if name doesnt exist, then fix it\n",
    "    if disorder['name'] == '' or disorder['name'] == ' ':\n",
    "        disorder['name'] = fix_empty_name_disorders(disorder)\n",
    "\n",
    "    # find name in the table of contents\n",
    "    for subchild in toc_node.children:\n",
    "\n",
    "        # if its exact name\n",
    "        involved_nodes += findall(\n",
    "            subchild, \n",
    "            filter_=lambda node: disorder['name'] == node.name\n",
    "        )\n",
    "        if len(involved_nodes) == 0:\n",
    "            # if its exact name\n",
    "            involved_nodes += findall(\n",
    "                subchild, \n",
    "                filter_=lambda node: disorder['name'] == node.parent.name + \" \" + node.name\n",
    "            )\n",
    "        if len(involved_nodes) == 0:\n",
    "            # if not exact name\n",
    "            involved_nodes += findall(\n",
    "                subchild, \n",
    "                filter_=lambda node: \n",
    "                disorder['name'] in node.parent.name + \" \" + node.name or \n",
    "                disorder['name'] in node.name + \" \" + node.parent.name\n",
    "            )\n",
    "\n",
    "    # catch errors before going further\n",
    "    if len(involved_nodes) == 0:\n",
    "        print(\"Error: Disease '\" + disorder['name'] + \"' was not found in Table of Contents.\")\n",
    "        continue\n",
    "    if len(involved_nodes) > 1:\n",
    "        print(\"Error: Disease '\" + disorder['name'] + \"' was found more than once in Table of Contents.\")\n",
    "        continue\n",
    "\n",
    "    # further post-processing\n",
    "    node = involved_nodes[0]\n",
    "    if 'sections' in disorder and disorder['sections'] != []:\n",
    "        node.children = [\n",
    "            Node(name=key, body=val, type=\"section\")\n",
    "            for key, val in disorder['sections'].items()\n",
    "        ]\n",
    "    for key, val in disorder.items():\n",
    "        if key == 'name':\n",
    "            pass\n",
    "        setattr(node, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05dc7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dsm_v/dsm_v.json', 'w+') as f:\n",
    "    json.dump(exporter.export(toc_node), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563f680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d284ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
